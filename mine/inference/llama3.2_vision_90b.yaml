model_name_or_path: meta-llama/Llama-3.2-90B-Vision-Instruct
quantization_bit: 4
quantization_method: bitsandbytes
#adapter_name_or_path:
template: mllama
#cache_dir: /workspace/llama_factory/.cache/huggingface
cache_dir: /workspace/huggingface
infer_backend: huggingface  # choices: [huggingface, vllm]
#trust_remote_code: true

